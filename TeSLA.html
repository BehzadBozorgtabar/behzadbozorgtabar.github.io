<!--This HTML is based on Taesung Park's project page. Code from w3schools was also used.-->
<script src="https://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
    body {
        font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        font-weight:300;
        font-size:18px;
        margin-left: auto;
        margin-right: auto;
        width: 1100px;
    }
    h1 {
        font-weight:300;
    }

    .disclaimerbox {
        background-color: #eee;
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
        padding: 20px;
    }

    video.header-vid {
        height: 140px
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.header-img {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.rounded {
        border: 0px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    a:link,a:visited
    {
        color: #1367a7;
        text-decoration: none;
    }
    a:hover {
        color: #208799;
    }

    td.dl-link {
        height: 160px;
        text-align: center;
        font-size: 22px;
    }

    .res_wrapper{
        text-align: center;
        float: left;
        margin-left: 3px;
    }

    .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
                15px 15px 0 0px #fff, /* The fourth layer */
                15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
                20px 20px 0 0px #fff, /* The fifth layer */
                20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
                25px 25px 0 0px #fff, /* The fifth layer */
                25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
        margin-left: 10px;
        margin-right: 45px;
    }

    .paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

        margin-left: 10px;
        margin-right: 45px;
    }

    .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
        margin-top: 5px;
        margin-left: 10px;
        margin-right: 30px;
        margin-bottom: 5px;
    }

    .vert-cent {
        position: relative;
        top: 50%;
        transform: translateY(-50%);
    }

    hr
    {
        border: 0;
        height: 1px;
        background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }

    .collapsible {
        background-color: #777;
        color: white;
        cursor: pointer;
        padding: 18px;
        width: 100%;
        border: none;
        text-align: left;
        outline: none;
        font-size: 20px;
    }

    .active, .collapsible:hover {
        background-color: #555;
    }

    .collapsible:after {
        content: '\002B';
        color: white;
        font-weight: bold;
        float: right;
        margin-left: 5px;
    }

    .active:after {
        content: "\2212";
    }

    .content {
        display: none;
        overflow: hidden;
        background-color: #f1f1f1;
    }

</style>

<html>
<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-176302866-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-176302866-1');
    </script>

    <title>TeSLA: Test-Time Self-Learning With Automatic Adversarial Augmentation</title>
    <meta property="og:image" content="" />
    <meta property="og:title" content="TeSLA: Test-Time Self-Learning With Automatic Adversarial Augmentation. In CVPR, 2023." />
</head>

<body>
<br>
<center>
    <span style="font-size:38px"> <img style="width:100px; height:100px;" class="middle" src="images/tesla.gif"><br> TeSLA: Test-Time Self-Learning With Automatic Adversarial Augmentation</span><br>
    <table align=center width=1100px>
        <tr>
            <td align=center width=275px>
              <span style="font-size:24px"><a href="https://people.epfl.ch/devavrat.tomar?lang=en">Devavrat Tomar</a></span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              <span style="font-size:24px"><a href="https://people.epfl.ch/guillaume.vray?lang=en&cvlang=en">Guillaume Vray</a></span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                <span style="font-size:24px"><a href="https://behzadbozorgtabar.com/">Behzad Bozorgtabar</a></span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                <span style="font-size:24px"><a href="https://people.epfl.ch/jean-philippe.thiran">Jean-Philippe Thiran</a></span>
            </td>
        </tr>
    </table>
    <table align=center width=700px>
        <tr>
            <td align=center width=10px>
                <center>
                    <span style="font-size:20px"></span>
                </center>
            </td>
            <td align=center width=225px>
                <center>
                    <span style="font-size:24px">EPFL</span>
                </center>
            </td>
            <td align=center width=225px>
                <center>
                    <span style="font-size:24px">CHUV</span>
                </center>
            </td>
            <td align=center width=10px>
                <center>
                    <span style="font-size:24px"></span>
                </center>
            </td>
        </tr>
    </table>

    <span style="font-size:24px"> <a href="http://arxiv.org/abs/2303.09870">paper</a> </span><br>
    <span style="font-size:24px"> CVPR 2023 </span>


</center>

<br>

<table align=center width=550px>
    <tr>
        <td align=center width=550px>
            <center>
        <td><img class="round" style="width:550px" src="images/TeSLA_main.png"/></td>
        </center>
        </td>
    </tr>
    <hr>
<!--<div class="column-right pxb">
<table align="center" width="700px">
    <tbody>
    <tr><center><a href="http://efrosgans.eecs.berkeley.edu/HessianPenalty/hessian_penalty_90sec_talk.mov">Download video</a></center></tr>
    <tr>
        <td align="center" width="700px">
            <center>
                <iframe width="700" height="394" src="https://www.youtube.com/embed/jPl-0EN6S1w" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </center>
        </td>
    </tr></tbody></table>
<hr>
</div>-->
<table align=center width=900px>
    <center><h1>Abstract</h1></center>
    <tr>
      Most recent test-time adaptation methods focus on only classification tasks, use specialized network architectures, destroy model calibration or rely on lightweight information from the source domain. To tackle these issues, this paper proposes a novel <b>Te</b>st-time <b>S</b>elf-<b>L</b>earning method with automatic <b>A</b>dversarial augmentation dubbed <b>TeSLA</b> for adapting a pre-trained source model to the unlabeled streaming test data. In contrast to conventional self-learning methods based on cross-entropy, we introduce a new test-time loss function through an implicitly tight connection with the mutual information and online knowledge distillation. Furthermore, we propose a learnable efficient adversarial augmentation module that further enhances online knowledge distillation by simulating high entropy augmented images. Our method achieves state-of-the-art classification and segmentation results on several benchmarks and types of domain shifts, particularly on challenging measurement shifts of medical images. TeSLA also benefits from several desirable properties compared to competing methods in terms of calibration, uncertainty metrics, insensitivity to model architectures, and source training strategies, all supported by extensive ablations.
        <br>
    </tr>
    <br>
    <hr>
<!--<div class="column-right pxb">
    <center><h1>Video (10 min)</h1></center>
    <table align="center" width="700px">
        <tbody>
        <tr><center><a href="http://efrosgans.eecs.berkeley.edu/HessianPenalty/hessian_penalty_spotlight_talk.mp4">Download video</a></center></tr>
        <tr>
            <td align="center" width="700px">
                <center>
                    <iframe width="700" height="394" src="https://www.youtube.com/embed/uZyIcTkSSXA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </center>
            </td>
        </tr></tbody></table>
    <hr>
</div>-->
<!-- <tr><center>
    <center><h1>Complete Results</h1></center>
    <p>
        Below, we show <i>all</i> z components learned by (1) ProGAN fine-tuned with the Hessian Penalty, (2) ProGAN trained from scratch with the Hessian Penalty, (3) ProGAN trained with InfoGAN loss and (4) vanilla ProGAN. Each row corresponds to varying a single z component from -2 to +2, leaving the remaining ones fixed. Different columns in the same row re-sample the fixed z components. All models were trained with 12-dimensional latent z vectors---with the exception of CLEVR-U which used |z|=3---hence why there are 12 rows. These results are <b>not</b> cherry-picked.
    </p>
    <table align=center width=800px>
        <tr>
            <td>
                <button class="collapsible">Edges+Shoes </button>
                <div class="content">
                    <h1 align=center>Edges+Shoes</h1>
                    <div class="res_wrapper"><video controls autoplay loop muted class="rounded" src="images/hessian_visuals/edgeshoes/e2s_ft_025656/seed_0/z000_to_z012.mp4"  style="width:195px"></video><p>Hessian Penalty<br>(Fine-Tuned)</p></div>
                <div class="res_wrapper"><video controls autoplay loop muted class="rounded" src="images/hessian_visuals/edgeshoes/e2s_fs_025656/seed_0/z000_to_z012.mp4"  style="width:195px"></video><p>Hessian Penalty</p></div>
                <div class="res_wrapper"><video controls autoplay loop muted class="rounded" src="images/hessian_visuals/edgeshoes/e2s_info_025355/seed_0/z000_to_z012.mp4"  style="width:195px"></video><p>InfoGAN</p></div>
                <div class="res_wrapper"><video controls autoplay loop muted class="rounded" src="images/hessian_visuals/edgeshoes/e2s_bl_024149_wandb_ver/seed_0/z000_to_z012.mp4"  style="width:195px"></video><p>Vanilla</p></div>
                </div>
            </td>
        </tr>
        <tr>
            <td>
                <button class="collapsible">CLEVR-Simple</button>
                <div class="content">
                <h1 align=center>CLEVR-Simple</h1>
                <div class="res_wrapper"><video controls autoplay loop muted class="rounded" src="images/hessian_visuals/clevr_simple/simple_ft_033795/seed_0/z000_to_z012.mp4"  style="width:195px"></video><p>Hessian Penalty<br>(Fine-Tuned)</p></div>
                <div class="res_wrapper"><video controls autoplay loop muted class="rounded" src="images/hessian_visuals/clevr_simple/simple_fs_033192/seed_0/z000_to_z012.mp4"  style="width:195px"></video><p>Hessian Penalty</p></div>
                <div class="res_wrapper"><video controls autoplay loop muted class="rounded" src="images/hessian_visuals/clevr_simple/simple_info_032589/seed_0/z000_to_z012.mp4"  style="width:195px"></video><p>InfoGAN</p></div>
                <div class="res_wrapper"><video controls autoplay loop muted class="rounded" src="images/hessian_visuals/clevr_simple/simple_bl_031685/seed_0/z000_to_z012.mp4"  style="width:195px"></video><p>Vanilla</p></div>
                </div>
            </td>
        </tr>
        <tr>
            <td>
                <button class="collapsible">CLEVR-1FOV</button>
                <div class="content">
                <h1 align=center>CLEVR-1FOV</h1>
                <div class="res_wrapper"><video controls autoplay loop muted class="rounded" src="images/hessian_visuals/clevr_1fov/1fov_ft/seed_0/z000_to_z012.mp4"  style="width:195px"></video><p>Hessian Penalty<br>(Fine-Tuned)</p></div>
                <div class="res_wrapper"><video controls autoplay loop muted class="rounded" src="images/hessian_visuals/clevr_1fov/1fov_fs/seed_0/z000_to_z012.mp4"  style="width:195px"></video><p>Hessian Penalty</p></div>
                <div class="res_wrapper"><video controls autoplay loop muted class="rounded" src="images/hessian_visuals/clevr_1fov/1fov_info/seed_0/z000_to_z012.mp4"  style="width:195px"></video><p>InfoGAN</p></div>
                <div class="res_wrapper"><video controls autoplay loop muted class="rounded" src="images/hessian_visuals/clevr_1fov/1fov_bl_BEST/seed_0/z000_to_z012.mp4"  style="width:195px"></video><p>Vanilla</p></div>
                </div>
            </td>
        </tr>
        <tr>
            <td>
                <button class="collapsible">CLEVR-U</button>
                <div class="content">
                <h1 align=center>CLEVR-U</h1>
                <div class="res_wrapper"><video controls autoplay loop muted class="rounded" src="images/hessian_visuals/clevr_u/underparam_ft_034966/seed_0/z000_to_z003.mp4"  style="width:195px"></video><p>Hessian Penalty<br>(Fine-Tuned)</p></div>
                <div class="res_wrapper"><video controls autoplay loop muted class="rounded" src="images/hessian_visuals/clevr_u/underparam_fs_036507/seed_0/z000_to_z003.mp4"  style="width:195px"></video><p>Hessian Penalty</p></div>
                <div class="res_wrapper"><video controls autoplay loop muted class="rounded" src="images/hessian_visuals/clevr_u/underparam_info_030781/seed_0/z000_to_z003.mp4"  style="width:195px"></video><p>InfoGAN</p></div>
                <div class="res_wrapper"><video controls autoplay loop muted class="rounded" src="images/hessian_visuals/clevr_u/underparam_bl/seed_0/z000_to_z003.mp4"  style="width:195px"></video><p>Vanilla</p></div>
                </div>
            </td>
        </tr>
        <tr>
            <td>
                <button class="collapsible">CLEVR-Complex</button>
                <div class="content">
                <h1 align=center>CLEVR-Complex</h1>
                <div class="res_wrapper"><video controls autoplay loop muted class="rounded" src="images/hessian_visuals/clevr_complex/two_obj_ft/seed_0/z000_to_z012.mp4"  style="width:195px"></video><p>Hessian Penalty<br>(Fine-Tuned)</p></div>
                <div class="res_wrapper"><video controls autoplay loop muted class="rounded" src="images/hessian_visuals/clevr_complex/two_obj_fs_036206/seed_0/z000_to_z012.mp4"  style="width:195px"></video><p>Hessian Penalty</p></div>
                <div class="res_wrapper"><video controls autoplay loop muted class="rounded" src="images/hessian_visuals/clevr_complex/two_obj_info_016010/seed_0/z000_to_z012.mp4"  style="width:195px"></video><p>InfoGAN</p></div>
                <div class="res_wrapper"><video controls autoplay loop muted class="rounded" src="images/hessian_visuals/clevr_complex/two_obj_bl_013297/seed_0/z000_to_z012.mp4"  style="width:195px"></video><p>Vanilla</p></div>
                </div>
            </td>
        </tr>

    </table>

    <hr>
<!-- </center></tr> -->
<center><h1>TeSLA Overview</h1></center>


<p> Below, we illustrate an overview of the <b>TeSLA</b> pipeline for adapting a pre-trained source model to the unlabeled streaming
test data. We introduce the concept of flipped cross-entropy (<i>f-<span class="math inline">‚ÑÇùîº</span></i>) loss for test-time training through the tight connection with the mutual information between the model's predictions and the test images.
Using this equivalence, we derive our test-time loss function that implicitly incorporates teacher-student knowledge distillation. Subsequently, we propose to enhance the test-time teacher-student knowledge distillation by utilizing the consistency of the student model's predictions on the proposed adversarial augmentations with their corresponding refined soft-pseudo labels from the teacher model. We refine the soft-pseudo labels by averaging the teacher model's predictions on (1) weakly augmented test images; (2) nearest neighbors in the feature space. Furthermore, we propose an efficient online algorithm for learning adversarial augmentations.</br>

<b>(a)</b> The student model <span class="math inline"><em>f</em><sub><em>s</em></sub></span>  is adapted on the test images by minimizing the proposed test-time objective <span class="math inline">‚Ñí<sub>pl</sub></span>. The high-quality soft-pseudo labels required by <span class="math inline">‚Ñí<sub>pl</sub></span> are obtained from the exponentially weighted averaged teacher model <span class="math inline"><em>f</em><sub><em>t</em></sub></span> and refined using the proposed Soft-Pseudo Label Refinement (PLR) on the corresponding test images. The soft-pseudo labels are further utilized for teacher-student knowledge distillation via <span class="math inline">‚Ñí<sub>kd</sub></span> on the adversarially augmented views of the test images. <b>(b)</b> The adversarial augmentations are obtained by applying learned sub-policies sampled i.i.d from <span class="math inline">‚Ñô</span> using the probability distribution <span class="math inline"><em>P</em></span> with their corresponding magnitudes selected from <span class="math inline"><em>M</em></span>. The parameters <span class="math inline"><em>M</em></span> and <span class="math inline"><em>P</em></span> of the augmentation module are updated by the <i>unbiased gradient estimator</i> of the proposed loss <span class="math inline">‚Ñí<sub>Aug</sub></span> computed on the augmented test images.

</p>

<table align=center width=900px>
    <tr>
        <td align=center width=900px>
            <center>
        <td><img class="round" style="width:900px" src="images/self_learning.png"/></td>
        </center>
        </td>
    </tr>


</table>


<hr>
    <center><h1>TeSLA Results</h1></center>

    <p>We evaluate and compare <b>TeSLA</b> against state-of-the-art (SOTA) test-time adaptation algorithms for both classification and segmentation tasks under three types of test-time distribution shifts resulting from (1) <b>common image corruption</b>, (2) <b>synthetic to real data transfer</b>, and (3) <b>measurement shifts</b> on medical images. The latter is characterized by a change in medical imaging systems, e.g., different scanners across hospitals or various staining techniques. </br>


<table align=center width=900px>
    <tr>
        <td align=center width=900px>
            <center>
        <td><img class="round" style="width:900px" src="images/TeSLA_1.png"/></td>
        </center>
        </td>
    </tr>


</table>

<table align=center width=400px>
    <tr>
        <td align=center width=400px>
            <center>
        <td><img class="round" style="width:400px" src="images/TeSLA_2.png"/></td>
        </center>
        </td>
    </tr>


</table>

</p>
<hr>

<center><h1>Try our code</h1></center>

<p>We released PyTorch code and models of the TeSLA for your use. </p>
<!-- <tr><center>
<table align=center width=900px>
    <tr>
        <td align=center width=900px>
            <center>
        <td><img class="round" style="width:900px" src="images/hessian_code.png"/></td>
        </center>
        </td>
    </tr>
</table>
<!-- </center></tr> -->
<table align=center width=800px>
    <tr><center>
    <span style="font-size:28px"> <a href='https://github.com/devavratTomar/TeSLA'> [GitHub] </a>
                <br></span>
    </center></tr>
    <!-- <tr><center> -->
    <!-- <span style="font-size:28px"><a>&nbsp;Model: [Prototxt] Weights: [Unrescaled] [Rescaled]</a></span> -->
    <!-- </center></tr> -->
</table>

<br>
<table align=center width=475 px>
    <hr>
    <center><h1>Paper</h1></center>
    <tr>
        <td><a href="http://arxiv.org/abs/2303.09870"><img class="layered-paper-big" style="height:175px" src="images/TeSLA_first_page.png"/></a></td>
        <td><span style="font-size:12pt">D. Tomar, G. Vray, B. Bozorgtabar, J.P. Thiran</span><br>
            <span style="font-size:12pt"><b>TeSLA: Test-Time Self-Learning With Automatic Adversarial Augmentation.</b></span><br>
            <span style="font-size:12pt">In CVPR, 2023.</span>
            <span style="font-size:12pt"><a href="http://arxiv.org/abs/2303.09870">ArXiv</a></span>
        </td>
        </td>
    </tr>
</table>
<br>
<div class="white_section_nerf wf-section">
<div class="citation w-container"><h2 class="grey-heading_nerf">BibTeX</h2>
<p class="paragraph-3 nerf_text nerf_results_text citation">@inproceedings{tomar2023TeSLA,<br/>
&emsp;&emsp;title={TeSLA: Test-Time Self-Learning With Automatic Adversarial Augmentation},
<br/>&emsp;&emsp;author={Tomar, Devavrat and Vray, Guillaume and Bozorgtabar, Behzad and Thiran, Jean-Philippe},<br/>&emsp;&emsp;booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR)},<br/>&emsp;&emsp;year={2023}<br/>}</p></div>

</div>
</div>

<!--
<table align=center width=600px>
    <tr>
        <td><span style="font-size:14pt"><center>
        <a href="images/OptTTA_bibitex.txt">[Bibtex]</a>
        </center></span></td>
    </tr>
</table>
<!-- </center></tr> -->

<!--
    <hr>

    <center><h1>Try our code</h1></center>

    <p>We released PyTorch code and pre-trained models of the OptTTA for your use. </p>
<!-- <tr><center>
    <table align=center width=900px>
        <tr>
            <td align=center width=900px>
                <center>
            <td><img class="round" style="width:900px" src="images/hessian_code.png"/></td>
            </center>
            </td>
        </tr>
    </table>
<!--<!-- </center></tr> -->
<!--
    <br>
    <table align=center width=475 px>
        <hr>
        <center><h1>Paper</h1></center>
        <tr>
            <td><a href="https://openreview.net/pdf?id=B6HdQaY_iR"><img class="layered-paper-big" style="height:175px" src="images/ScoreNet_first_page.png"/></a></td>
            <td><span style="font-size:12pt">T. Stegm√ºller, B. Bozorgtabar, A. Spahr, J.P. Thiran</span><br>
                <span style="font-size:12pt"><b>ScoreNet: Learning Non-Uniform Attention and Augmentation for Transformer-Based Histopathological Image Classification.</b></span><br>
                <span style="font-size:12pt">In WACV, 2023.</span>
                <span style="font-size:12pt"><a href="https://arxiv.org/pdf/2202.07570.pdf">arXiv</a></span>
            </td>
            </td>
        </tr>
    </table>
    <br>
    <div class="white_section_nerf wf-section">
	 <div class="citation w-container"><h2 class="grey-heading_nerf">BibTeX</h2>
	 <p class="paragraph-3 nerf_text nerf_results_text citation">@inproceedings{Stegm√ºller2023scorenet,<br/>
	 &emsp;&emsp;title={ScoreNet: Learning Non-Uniform Attention and Augmentation for Transformer-Based Histopathological Image Classification},
	 <br/>&emsp;&emsp;author={Stegm√ºller, Thomas and Bozorgtabar, Behzad and Spahr, Antoine and Thiran, Jean-Philippe},<br/>&emsp;&emsp;booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},<br/>&emsp;&emsp;year={2023}<br/>}</p></div>

	</div>
	</div>

<!--
    <table align=center width=600px>
        <tr>
            <td><span style="font-size:14pt"><center>
				  	<a href="images/OptTTA_bibitex.txt">[Bibtex]</a>
            </center></span></td>
        </tr>
    </table>
  <!-- </center></tr> -->
  <!-- </center></tr> -->
    <br>
    <hr>

    <table align=center width=1100px>
        <tr>
            <td width=400px>
                <left>
                    <center><h1>Acknowledgements</h1></center>
                    We thank Taesung Park for his project page template.
                </left>
            </td>
        </tr>
    </table>
</table>


<br><br>

    <script>
        var coll = document.getElementsByClassName("collapsible");
        var i;

        for (i = 0; i < coll.length; i++) {
            coll[i].addEventListener("click", function() {
                this.classList.toggle("active");
                var content = this.nextElementSibling;
                if (content.style.display === "block") {
                    content.style.display = "none";
                } else {
                    content.style.display = "block";
                }
            });
        }
    </script>

</body>
</html>
