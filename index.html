<!DOCTYPE html>
<html>
    <head>
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-176302866-1"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'UA-176302866-1');
        </script>

        <meta charset="utf-8">
        <title>Behzad Bozorgtabar</title>
        <meta name="description" content="Project Page">
        <link rel="stylesheet" href="main.css">
        <link rel="stylesheet" href="https://use.typekit.net/oml3bsz.css">
    </head>
    <body>
        <h1>
            Behzad Bozorgtabar
        </h1><br>
        <h3> Computer Vision Group Leader & Lecturer at EPFL<br>
          Senior Scientist at CHUV-EPFL </h3><br>
        <div class="row">
            <div class="column-left">
                <img class="me" src="images/BBB.png" alt="Behzad Bozorgtabar"><br>
                email: behzad.bozorgtabar [at] epfl [dot] ch <br>
                <p> <a href="https://scholar.google.com/citations?user=kxAk6AoAAAAJ"><img src="./pic/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
        					<a href="https://github.com/BehzadBozorgtabar"><img src="./pic/github_s.jpg" height="30px" style="margin-bottom:-3px"></a>
                  <a href="https://dblp.org/pid/59/10419.html"><img src="./pic/dblp.png" height="30px" style="margin-bottom:-3px"></a>
                  <a href="https://www.linkedin.com/in/behzad-bozorgtabar-72838560/"><img src="./pic/LinkedIn_s.png" height="30px" style="margin-bottom:-3px"></a>
        				</p>
            </div>
            <!--<div class="column-right pxb">
            <a href="https://github.com/BehzadBozorgtabar/SELF-TAUGHT-SEMI-SUPERVISED-ANOMALY-DETECTION">github</a></span></p>
                <h1>THE PIXEL BENDING BLOG</h1>
                <p>Welcome to the Pixel Bending mini-blog! Here, I'll talk about various topics related to synthesizing images,
                    building deep generative models and more. Click the links below to access the posts:</p>
                <a class="disentangle-button gradient-button" href="blog_posts/disentanglement.html">1. THE MAGIC OF DISENTANGLEMENT</>
                <a class="hessian-button gradient-button">2. THE HESSIAN PENALTY</a>
            </div>-->
            <div class="announcement-box">
    <h1>ANNOUNCEMENT</h1>

    <p>
        <strong>I am currently looking for a PhD student with a focus on VLMs (Vision-Language Models). If you're interested, please reach out to me!</strong>
    </p>
</div>


      <!--      <div class="column-right pxb">
      <h1>ANNOUNCEMENT</h1>

      <p style="line-height: 60px; display: flex; align-items: center;">
          <b>I am currently looking for a PhD student with the focus on VLMs. If you're interested, please reach out to me.</b>
      </p><br>

 <!--
      <h1>RESEARCH UPDATES</h1>

      <p style="line-height: 60px; display: flex; align-items: center;">
          <img style="width: 60px; height: 60px; vertical-align: middle; margin-right: 10px;" src="images/unmix_tns.gif">
          <b>ICLR 2024 paper: 'Un-Mixing Test-Time Normalization Statistics: Combatting Label Temporal Correlation'</b>
      </p><br>
      <a class="disentangle-button gradient-button" href="UnMix-TNS.html">UnMix-TNS</a>

      <p style="line-height: 60px; display: flex; align-items: center;">
          <img style="width: 60px; height: 60px; vertical-align: middle; margin-right: 10px;" src="images/cribo_logo.png">
          <b>ICLR 2024 paper: 'CrIBo: Self-Supervised Learning via Cross-Image Object-Level Bootstrapping'</b>
      </p><br>
      <a class="disentangle-button gradient-button" href="CrIBo.html">CrIBo</a>

  </div>
  -->

  </div>

        <br>
        <h2 style="background: linear-gradient(180deg, rgba(255,255,255,0) 65%, #ff8888 65%);">About Me</h2><br>

        I'm a senior scientist and lecturer at the Signal Processing Lab (LTS5) at the École Polytechnique Fédérale de Lausanne (EPFL), with a joint affiliation with the Department of Radiology at the Lausanne University Hospital (CHUV) in Lausanne, Switzerland. At the EPFL-LTS5, I am the computer vision team leader for the medical imaging group. I am a member of <a href="https://ellis.eu/members"> European Lab for Learning & Intelligent Systems (ELLIS)</a> and <a href="https://www.epfl.ch/research/domains/epfl-ellis/ellis-society-members/"> EPFL’s ELLIS Unit</a>. Earlier, I was a Postdoctoral Researcher at IBM Research-Australia.



          <p> My principal research area lies at the intersection of computer vision and medical image analysis and machine learning. I specialize in self-supervised learning methods that minimize reliance on extensive labeling, advancing vision-based applications. My work also focuses on improving AI adaptability and generalization through techniques like test-time adaptation and domain generalization, crucial for reliable performance in real-world applications.

</p><br><br>
        <h2 style="background: linear-gradient(180deg, rgba(255,255,255,0) 65%, #fffe8c 65%);">News</h2><br>

        <!--<b>[July 2020]</b> I started a blog! It's called Pixel Bending, and I'll be discussing various things related to generative models.
        The first two-part series is on disentanglement.<br>href="https://www.sciepublish.com/index/journals/editors/cvml/21.html">-->
        <font color="red">[Oct 2024]</font> A paper has been accepted to WACV 2025.<br>
        <b><font color="red">[Oct 2024]</font></b>  I have received the IEEE TMI Distinguished Reviewer award.<br>
        <b><font color="red">[Sep 2024]</font></b> I'll be serving as an Area Chair for CVPR 2025.<br>
        <b><font color="red">[July 2024]</font></b> Our joint paper on Generalized Zero Shot Chest X-ray Classification has been accepted by Transactions on Medical Imaging (T-MI).<br>
        <b><font color="red">[July 2024]</font></b> Our joint paper on active learning is now published in Medical Image Analysis (MedIA).<br>
        <b><font color="red">[July 2024]</font></b> I have been appointed as an Associate Editor of IET Computer Vision.<br>
        <b><font color="red">[May 2024]</font></b> I'll be serving as a reviewer for NeurIPS 2024.<br>
        <!--<b><b><font color="red">[Jan 2024]</font></b> Our paper 'UnMix-TNS', Un-Mixing Test-Time Normalization Statistics: Combatting Label Temporal Correlation has received acceptance from ICLR 2024.<br>
        <b><font color="red">[Jan 2024]</font></b> Our paper 'CrIBo', Self-Supervised Learning Via Cross-Image Object-Level Bootstrapping has received acceptance from ICLR 2024.<br>

        <!--<b><font color="red">[July 2023]</font></b> Our joint work with KU Leuven, AdaSim: Adaptive Similarity Bootstrapping for Self-Distillation based Representation Learning, has received acceptance from ICCV 2023.<br>
        <b><font color="red">[July 2023]</font></b> Our joint work with IBM Zurich Research Lab, Weakly Supervised Joint Whole-Slide Segmentation and Classification in Prostate Cancer, has received acceptance from journal of Medical Image Analysis (MedIA).<br>
        <!--<b><font color="red">[June 2023]</font></b> Two papers have received acceptance from MICCAI 2023.<br>
        <b><font color="red">[Feb 2023]</font></b> Our paper, TeSLA: Test-Time Self-Learning With Automatic Adversarial Augmentation, has received acceptance from CVPR 2023.<br>
        <b><font color="red">[Feb 2023]</font></b> Our paper, CrOC: Cross-View Online Clustering for Dense Visual Representation Learning, has received acceptance from CVPR 2023.<br>
        <!--<b>[<b>[Jan 2023]</b> Our joint work with the University of Bern, namely 'SAGTTA' on test-time augmentation, has been accepted to ISBI 2023.<br>
        [Nov 2022]</b> Our paper on self-supervised anomaly localization has received acceptance from AAAI 2023 (acceptance rate of 19.6%) (Oral).<br>
        <b>[Oct 2022]</b> Our paper won First Runner up award at the AIMIA Workshop at ECCV 2022.<br>
        <b>[Oct 2022]</b> Our new paper, ScoreNet, has received acceptance from WACV 2023.<br>
        <!--<b>[Sep 2022]</b> Our new paper on transformer-based anomaly detection and localization has received acceptance from BMVC 2022.<br>
        <!--<b><b>[Aug 2022]</b> My patent on system and method for domain adaptation has been published.</a><br>
        [<b>[Aug 2022]</b> Two papers have received acceptance from ECCV 2022  AIMIA Workshop</a>.<br>
        <b>[Aug 2022]</b> My patent on annotation-efficient image anomaly detection has been published.</a><br>
        July 2020]</b> I started a blog! It's called Pixel Bending, and I'll be discussing various things related to generative models.
        The first two-part series is on disentanglement.<br>href="https://www.sciepublish.com/index/journals/editors/cvml/21.html">
        <b>[May 2022]</b> I joined the editorial board of a Journal of Computer Vision and Machine Learning</a>.<br>
        <b>[Apr 2022]</b> Code for the OptTTA has been released in PyTorch <a href="https://github.com/devavratTomar/OptTTA"> here</a>.<br>
        <b>[Mar 2022]</b> Our new paper, OptTTA, has received acceptance from MIDL 2022 for an oral presentation.<br>-->


       <h2 style="background: linear-gradient(180deg, rgba(255,255,255,0) 65%, #cd8cff 65%);">EPFL Computer Vision Talks</h2><br>
       <p class="paper"><img src="images/TALKS.png"
                             alt="EPFL CV Talks.">
           <span><b>I am organizing the EPFL Computer Vision Talks</b>
       <br><a href="https://www.youtube.com/channel/UCAkp-rlUGYkpdIqmKezamWw/videos">YouTube Channel</a> </span></p>

       <h2 style="background: linear-gradient(180deg, rgba(255,255,255,0) 65%, #8ca9ff 65%);">Citations</h2><br>
       <p class="paper"><img src="images/citation_updated.png"
                             alt="citations.">
           <span><b>A complete list of my publications and patents can be found at </b>
       <a href="https://scholar.google.com/citations?view_op=list_works&hl=en&user=kxAk6AoAAAAJ&gmla=AJsN-F7ChUXZmlbUjbrqc1qsOC_ETzCYHSofHkiyiwD9wqLtXswlrGvYRW3LraC0IEF11euu9IZagFBrJWlAoI1OLnTW5ZUMHgLlhwyVYuys03rvbNlVlmzBpuKNVK9RSNOatjiKnp8r">Google Scholar</a> </span></p>



       <h2 style="background: linear-gradient(180deg, rgba(255,255,255,0) 65%, #93fc93 65%);">Recent Selected Publications</h2><br>

       <p class="paper"><img src="images/SimZSS.png"
                       alt="SimZSS">
       <span><b> A Simple Framework For Open-Vocabulary Zero-Shot Segmentation</b>
       <br>Thomas Stegmüller<sup>*</sup>, Tim Lebailly<sup>*</sup>, Nikola Dukic, <b>Behzad Bozorgtabar</b>, Tinne Tuytelaars, Jean-Philippe Thiran</b>
         <br>arXiv 2024
         <br>   <a href="https://arxiv.org/pdf/2406.16085">arXiv</a> </span></p>

       <p class="paper"><img src="images/unmix_tns.gif"
         width="200"
height="200" alt="UnMix">
       <span><b><font color="red">*New*</font> Un-Mixing Test-Time Normalization Statistics: Combatting Label Temporal Correlation</b>
       <br>Devavrat Tomar<sup>*</sup>, Guillaume Vray<sup>*</sup>, Jean-Philippe Thiran, <b>Behzad Bozorgtabar</b>
         <br>ICLR 2024
         <br>  <a href="UnMix-TNS.html">project page</a> &#183; <a href="https://openreview.net/pdf?id=xyxU99Nutg">paper</a> &#183; <a href="https://github.com/devavratTomar/unmixtns">github</a> </span></p>


         <p class="paper"><img src="images/CrIBo.png"
                         alt="CrIBo">
         <span><b><font color="red">*New*</font> CrIBo: Self-Supervised Learning via Cross-Image Object-Level Bootstrapping</b>
         <br>Tim Lebailly<sup>*</sup>, Thomas Stegmüller<sup>*</sup>, <b>Behzad Bozorgtabar</b>, Jean-Philippe Thiran, Tinne Tuytelaars</b>
           <br>ICLR 2024 (<b>Spotlight, Top 5%</b>)
           <br>  <a href="CrIBo.html">project page</a> &#183;  <a href="https://openreview.net/pdf?id=3M0GXoUEzP">paper</a> &#183; <a href="https://github.com/tileb1/CrIBo">github</a> </span></p>


      <p class="paper"><img src="images/Distill_SODA.png"
                       alt="Distill_SODA">
       <span><b><font color="red">*New*</font> Distill-SODA: Distilling Self-Supervised Vision Transformer for Source-Free Open-Set Domain Adaptation in Computational Pathology</b>
       <br>Guillaume Vray<sup>*</sup>, Devavrat Tomar<sup>*</sup>, Jean-Philippe Thiran, <b>Behzad Bozorgtabar</b>
       <br>IEEE Transactions on Medical Imaging (T-MI) 2024
       <br>   <a href="https://arxiv.org/pdf/2307.04596.pdf">paper</a> &#183; <a href="https://github.com/LTS5/Distill-SODA">github</a> </span></p>



       <p class="paper"><img src="images/iccv2023.png"
                       alt="Adasim">
       <span><b><font color="red">*New*</font> Adaptive Similarity Bootstrapping for Self-Distillation based Representation Learning</b>
       <br>Tim Lebailly<sup>*</sup>, Thomas Stegmüller<sup>*</sup>, <b>Behzad Bozorgtabar</b>, Jean-Philippe Thiran, Tinne Tuytelaars</b>
         <br>ICCV 2023
         <br>   <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Lebailly_Adaptive_Similarity_Bootstrapping_for_Self-Distillation_Based_Representation_Learning_ICCV_2023_paper.pdf">paper</a> &#183; <a href="https://github.com/tileb1/AdaSim">github</a></span></p>


        <p class="paper"><img src="images/CrOC_main.png"
                        alt="CrOC_main">
        <span><b> CrOC: Cross-View Online Clustering for Dense Visual Representation Learning</b>
        <br>Thomas Stegmüller<sup>*</sup>, Tim Lebailly<sup>*</sup>, <b>Behzad Bozorgtabar</b>, Tinne Tuytelaars, Jean-Philippe Thiran</b>
          <br>CVPR 2023
          <br>  <a href="CrOC.html">project page</a> &#183; <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Stegmuller_CrOC_Cross-View_Online_Clustering_for_Dense_Visual_Representation_Learning_CVPR_2023_paper.pdf">paper</a> &#183; <a href="https://github.com/stegmuel/CrOC">github</a></span></p>


        <p class="paper"><img src="images/TeSLA_main.png"
                        alt="TeSLA_main">
        <span><b>TeSLA: Test-Time Self-Learning With Automatic Adversarial Augmentation</b>
        <br>Devavrat Tomar, Guillaume Vray, <b>Behzad Bozorgtabar</b>, Jean-Philippe Thiran
          <br>CVPR 2023
          <br>   <a href="TeSLA.html">project page</a> &#183; <a href="https://arxiv.org/pdf/2303.09870.pdf">paper</a> &#183; <a href="https://github.com/devavratTomar/TeSLA">github</a></span></p>



          <p class="paper"><img src="images/amae.png"
                          alt="AMAE">
          <span><b> AMAE: Adaptation of Pre-Trained Masked Autoencoder for Dual-Distribution Anomaly Detection in Chest X-Rays</b>
          <br><b>Behzad Bozorgtabar</b>, Dwarikanath Mahapatra, Jean-Philippe Thiran</b>
            <br>MICCAI 2023
            <br>   <a href="https://arxiv.org/pdf/2307.12721.pdf">paper</a> </span></p>

        <p class="paper"><img src="images/scorenet_2.png"
                        alt="ScoreNet">
        <span><b>ScoreNet: Learning Non-Uniform Attention and Augmentation for <br>Transformer-Based Histopathological Image Classification</b>
        <br>Thomas Stegmüller, <b>Behzad Bozorgtabar</b>, Antoine Spahr, Jean-Philippe Thiran</b>
          <br>WACV 2023
          <br>  <a href="ScoreNet.html">project page</a> &#183; <a href="https://openaccess.thecvf.com/content/WACV2023/papers/Stegmuller_ScoreNet_Learning_Non-Uniform_Attention_and_Augmentation_for_Transformer-Based_Histopathological_Image_WACV_2023_paper.pdf">paper</a> &#183; <a href="https://github.com/stegmuel/ScoreNet">github</a> </span></p>

          <p class="paper"><img src="images/BMVC_2022.png"
                          alt="ANOM">
          <span><b>Anomaly Detection and Localization Using Attention-Guided Synthetic Anomaly <br>and Test-Time Adaptation</b>
          <br><b>Behzad Bozorgtabar</b>, Dwarikanath Mahapatra, Jean-Philippe Thiran</b>
            <br>BMVC 2022
            <br>  <a href="https://bmvc2022.mpi-inf.mpg.de/0472.pdf">paper</a>  </span></p>

              <p class="paper"><img src="images/optTTA.png"
                              alt="OptTTA">
            <span><b> OptTTA: Learnable Test-Time Augmentation for <br>Source-Free Medical Image Segmentation Under Domain Shift</b>
        <br>Devavrat Tomar, Guillaume Vray, Jean-Philippe Thiran, <b>Behzad Bozorgtabar</b>
                <br>MIDL 2022 (Oral)
                <br>   <a href="OptTTA.html">project page</a> &#183; <a href="https://openreview.net/pdf?id=B6HdQaY_iR">paper</a> &#183; <a href="https://github.com/devavratTomar/OptTTA">github</a></span></p>



                  <p class="paper"><img src="images/SRMA.png"
                                        alt="SRMA.">
                      <span><b> Self-Rule to Multi-Adapt: Generalized Multi-source Feature Learning <br>Using Unsupervised Domain Adaptation for Colorectal Cancer Tissue Detection</b>
                  <br>Christian Abbet, Linda Studer, Andreas Fischer, Heather Dawson, Inti Zlobec,<br>
                  <b>Behzad Bozorgtabar</b>, Jean-Philippe Thiran
                  <br>MedIA Journal 2022
                  <br> <a href="https://www.sciencedirect.com/science/article/pii/S1361841522001207?utm_campaign=STMJ_AUTH_SERV_PUBLISHED&utm_medium=email&utm_acid=90864309&SIS_ID=&dgcid=STMJ_AUTH_SERV_PUBLISHED&CMX_ID=&utm_in=DM256431&utm_source=AC_">paper</a> &#183;
                          <a href="https://github.com/christianabbet/SRA">github</a></span></p>

                      <p class="paper"><img src="images/wacv_2022.png"
                                                alt="SST.">
                              <span><b>Self-Supervised Generative Style Transfer for One-Shot Medical Image Segmentation</b>
                          <br>Devavrat Tomar, <b>Behzad Bozorgtabar</b>, Manana Lortkipanidze, Guillaume Vray, <br>Mohammad Saeed Rad, Jean-Philippe Thiran
                          <br>WACV 2022
                          <br> <a href="https://openaccess.thecvf.com/content/WACV2022/papers/Tomar_Self-Supervised_Generative_Style_Transfer_for_One-Shot_Medical_Image_Segmentation_WACV_2022_paper.pdf">paper</a> &#183;
                                  <a href="https://github.com/devavratTomar/SST/">github</a></span></p>

                                  <p class="paper"><img src="images/SegGini.png"
                                                            alt="SegGini.">
                                          <span><b>Learning Whole-Slide Segmentation from Inexact and <br> Incomplete Labels using Tissue Graphs</b>
                                      <br>Valentin Anklin, Pushpak Pati, Guillaume Jaume, <b>Behzad Bozorgtabar</b>, <br> Antonio Foncubierta-Rodríguez, Jean-Philippe Thiran, Mathilde Sibony,<br> Maria Gabrani, Orcun Goksel
                                      <br>MICCAI 2021
                                      <br> <a href="https://link.springer.com/content/pdf/10.1007/978-3-030-87196-3_59.pdf">paper</a> &#183;
                                              <a href="https://github.com/histocartography/histocartography">github</a></span></p>

                                    <p class="paper"><img src="images/SOoD.png"
                                                              alt="SOoD.">
                                                      <span><b>SOoD: Self-Supervised Out-of-Distribution Detection <br>Under Domain Shift for Multi-Class Colorectal Cancer Tissue Types</b>
                                                  <br><b>Behzad Bozorgtabar</b>, Guillaume Vray, Dwarikanath Mahapatra, Jean-Philippe Thiran
                                                  <br>ICCVW 2021
                                                  <br> <a href="https://openaccess.thecvf.com/content/ICCV2021W/CVAMD/papers/Bozorgtabar_SOoD_Self-Supervised_Out-of-Distribution_Detection_Under_Domain_Shift_for_Multi-Class_Colorectal_ICCVW_2021_paper.pdf">paper</a> &#183;
                                                          <a href="https://github.com/GuillaumeVray/SOoD">github</a></span></p>

                                                          <p class="paper"><img src="images/arxiv.png"
                                                                                    alt="CVPR2021.">
                                                                            <span><b>Quantifying Explainers of Graph Neural Networks in Computational Pathology</b>
                                                                        <br>Guillaume Jaume, Pushpak Pati, <b>Behzad Bozorgtabar</b>, Antonio Foncubierta-Rodríguez, <br>Florinda Feroce, Anna Maria Anniciello, Tilman Rau, Maria Gabrani, <br>Jean-Philippe Thiran, Orcun Goksel
                                                                        <br>CVPR 2021
                                                                        <br> <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Jaume_Quantifying_Explainers_of_Graph_Neural_Networks_in_Computational_Pathology_CVPR_2021_paper.pdf">paper</a> &#183;
                                                                                <a href="https://github.com/histocartography/patho-quant-explainer">github</a></span></p>


                                                                                <p class="paper"><img src="images/tmi.png"
                                                                                                          alt="T-MI.">
                                                                                                  <span><b>Self-Attentive Spatial Adaptive Normalization for Cross-Modality Domain Adaptation</b>
                                                                                              <br>Devavrat Tomar, Manana Lortkipanidze, Guillaume Vray, <br> <b>Behzad Bozorgtabar</b>, Jean-Philippe Thiran
                                                                                              <br>IEEE Transactions on Medical Imaging (T-MI) 2021
                                                                                              <br> <a href="https://ieeexplore.ieee.org/document/9354186">paper</a> &#183;
                                                                                                      <a href="https://github.com/devavratTomar/sasan">github</a></span></p>

                                                                                                      <p class="paper"><img src="images/midl.png"
                                                                                                                                alt="MIDL2021.">
                                                                                                                        <span><b>Self-Rule to Adapt: Learning Generalized Features from Sparsely-Labeled Data<br> Using Unsupervised Domain Adaptation for Colorectal Cancer Tissue Phenotyping</b>
                                                                                                                    <br>Christian Abbet, Linda Studer, Andreas Fischer, Heather Dawson, Inti Zlobec,<br>
                                                                                                                    <b>Behzad Bozorgtabar</b>, Jean-Philippe Thiran
                                                                                                                    <br>MIDL 2021
                                                                                                                    <br> <a href="https://2021.midl.io/proceedings/abbet21.pdf">paper</a> &#183;
                                                                                                                            <a href="https://github.com/christianabbet/SRA">github</a></span></p>

                                                                                                                            <p class="paper"><img src="images/isbi2021.png"
                                                                                                                                                      alt="ISBI2021.">
                                                                                                                                              <span><b>Self-Taught Semi-Supervised Anomaly Detection on Upper Limb X-rays</b>
                                                                                                                                          <br>Antoine Spahr , <b>Behzad Bozorgtabar</b>, Jean-Philippe Thiran
                                                                                                                                          <br>ISBI 2021
                                                                                                                                          <br> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9433771">paper</a>&#183;
                                                                                                                                          <a href="https://github.com/BehzadBozorgtabar/SELF-TAUGHT-SEMI-SUPERVISED-ANOMALY-DETECTION">github</a></span></p>


                                                                                                                                                  <p class="paper"><img src="images/wacv20.png"
                                                                                                                                                                            alt="ISBI2021.">
                                                                                                                                                                    <span><b>Benefiting from Bicubically Down-Sampled Images for <br>Learning Real-World Image Super-Resolution</b>
                                                                                                                                                                <br>Mohammad Saeed Rad, Thomas Yu, Claudiu Musat, Hazım Kemal Ekenel, <br> <b>Behzad Bozorgtabar</b>, Jean-Philippe Thiran
                                                                                                                                                                <br>WACV 2021
                                                                                                                                                                <br> <a href="https://openaccess.thecvf.com/content/WACV2021/papers/Rad_Benefiting_From_Bicubically_Down-Sampled_Images_for_Learning_Real-World_Image_Super-Resolution_WACV_2021_paper.pdf">paper</a>
                                                                                                                                                                    </span></p>

                                                                                                                                                                    <p class="paper"><img src="images/miccai20_1.png"
                                                                                                                                                                                              alt="SALAD.">
                                                                                                                                                                                      <span><b>SALAD: Self-Supervised Aggregation Learning for Anomaly Detection on X-Rays</b>
                                                                                                                                                                                  <br><b>Behzad Bozorgtabar</b>, Dwarikanath Mahapatra, Guillaume Vray, Jean-Philippe Thiran
                                                                                                                                                                                  <br>MICCAI 2020
                                                                                                                                                                                  <br> <a href="https://link.springer.com/content/pdf/10.1007%2F978-3-030-59710-8_46.pdf">paper</a> &#183;
                                                                                                                                                                                          <a href="https://github.com/GuillaumeVray/SALAD">github</a></span></p>

                                                                                                                                                                                          <p class="paper"><img src="images/miccai20_2.png"
                                                                                                                                                                                                                    alt="Self-Rule.">
                                                                                                                                                                                                            <span><b>Divide-and-Rule: Self- Supervised Learning for Survival Analysis in Colorectal Cancer</b>
                                                                                                                                                                                                        <br>Christian Abbet, Inti Zlobec, <b>Behzad Bozorgtabar</b>, Jean-Philippe Thiran
                                                                                                                                                                                                        <br>MICCAI 2020
                                                                                                                                                                                                        <br> <a href="https://link.springer.com/content/pdf/10.1007/978-3-030-59722-1_46.pdf">paper</a> &#183;
                                                                                                                                                                                                                <a href="https://github.com/christianabbet/DnR">github</a></span></p>


                                                                                                                                                                                                                <p class="paper"><img src="images/cvpr2020.png"
                                                                                                                                                                                                                                          alt="CVPR2020.">
                                                                                                                                                                                                                                  <span><b>Pathological Retinal Region Segmentation From OCT Images <br>Using Geometric Relation Based Augmentation</b>
                                                                                                                                                                                                                              <br>Dwarikanath Mahapatra, <b>Behzad Bozorgtabar</b>, Jean-Philippe Thiran, Ling Shao
                                                                                                                                                                                                                              <br>CVPR 2020
                                                                                                                                                                                                                              <br> <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Mahapatra_Pathological_Retinal_Region_Segmentation_From_OCT_Images_Using_Geometric_Relation_CVPR_2020_paper.pdf">paper</a>


                                                                                                                                                                                                                              <p class="paper"><img src="images/syndemo.png"
                                                                                                                                                                                                                                                        alt="Syndemo.">
                                                                                                                                                                                                                                                <span><b>SynDeMo: Synergistic Deep Feature Alignment for Joint Learning of Depth and Ego-Motion</b>
                                                                                                                                                                                                                                            <br><b>Behzad Bozorgtabar</b>, Mohammad Saeed Rad, Dwarikanath Mahapatra, Jean-Philippe Thiran
                                                                                                                                                                                                                                            <br>ICCV 2019
                                                                                                                                                                                                                                            <br> <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Bozorgtabar_SynDeMo_Synergistic_Deep_Feature_Alignment_for_Joint_Learning_of_Depth_ICCV_2019_paper.pdf">paper</a> &#183;
                                                                                                                                                                                                                                                    <a href="http://openaccess.thecvf.com/content_ICCV_2019/supplemental/Bozorgtabar_SynDeMo_Synergistic_Deep_ICCV_2019_supplemental.pdf">supplementary material</a></span></p>


                                                                                                                                                                                                                                                    <p class="paper"><img src="images/srobb.png"
                                                                                                                                                                                                                                                                              alt="SROBB.">
                                                                                                                                                                                                                                                                      <span><b>SROBB: Targeted Perceptual Loss for Single Image Super-Resolution</b>
                                                                                                                                                                                                                                                                  <br>Mohammad Saeed Rad, <b>Behzad Bozorgtabar</b>, Urs-Viktor Marti, <br> Max Basler, Hazım Kemal Ekenel, <br>Jean-Philippe Thiran
                                                                                                                                                                                                                                                                  <br>ICCV 2019
                                                                                                                                                                                                                                                                  <br> <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Rad_SROBB_Targeted_Perceptual_Loss_for_Single_Image_Super-Resolution_ICCV_2019_paper.pdf">paper</a> &#183;
                                                                                                                                                                                                                                                                          <a href="http://openaccess.thecvf.com/content_ICCV_2019/supplemental/Rad_SROBB_Targeted_Perceptual_ICCV_2019_supplemental.pdf">supplementary material</a></span></p>


                                                                                                                                                                                                                                                                          <p class="paper"><img src="images/fg19.png"
                                                                                                                                                                                                                                                                                                    alt="FG2019.">
                                                                                                                                                                                                                                                                                            <span><b>Using Photorealistic Face Synthesis and Domain Adaptation <br>to Improve Facial Expression Analysis</b>
                                                                                                                                                                                                                                                                                        <br><b>Behzad Bozorgtabar</b>, Mohammad Saeed Rad, Hazım Kemal Ekenel, Jean-Philippe Thiran
                                                                                                                                                                                                                                                                                        <br>FG 2019
                                                                                                                                                                                                                                                                                        <br> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8756632&tag=1">paper</a> &#183;
                                                                                                                                                                                                                                                                                                <a href="https://github.com/BehzadBozorgtabar/FSDA">github</a></span></p>


                                                                                                                                                                                                                                                                                                <p class="paper"><img src="images/l2s19.jpg"
                                                                                                                                                                                                                                                                                                                          alt="CVIU2019.">
                                                                                                                                                                                                                                                                                                                  <span><b>Learn to Synthesize and Synthesize to Learn</b>
                                                                                                                                                                                                                                                                                                              <br><b>Behzad Bozorgtabar</b>, Mohammad Saeed Rad, Hazım Kemal Ekenel, Jean-Philippe Thiran
                                                                                                                                                                                                                                                                                                              <br>CVIU 2019
                                                                                                                                                                                                                                                                                                              <br> <a href="https://www.sciencedirect.com/science/article/pii/S1077314219300657?via%3Dihub">paper</a> &#183;
                                                                                                                                                                                                                                                                                                                      <a href="https://github.com/BehzadBozorgtabar/Learn-to-Synthesize-and-Synthesize-to-Learn">github</a></span></p>



                                                                                                                                                                                                                                                                                                                      <p class="paper"><img src="images/NeurIPS18.png"
                                                                                                                                                                                                                                                                                                                                                alt="NeurIPS18.">
                                                                                                                                                                                                                                                                                                                                        <span><b>Image-Level Attentional Context Modeling Using Nested-Graph Neural Networks</b>
                                                                                                                                                                                                                                                                                                                                    <br>Guillaume Jaume, <b>Behzad Bozorgtabar</b>, Hazım Kemal Ekenel, <br>Jean-Philippe Thiran, Maria Gabrani
                                                                                                                                                                                                                                                                                                                                    <br>NeurIPS 2018
                                                                                                                                                                                                                                                                                                                                    <br> <a href="https://arxiv.org/pdf/1811.03830.pdf">paper</a>


                                                                                                                                                                                                                                                                                                                                    <p class="paper"><img src="images/msmct.png"
                                                                                                                                                                                                                                                                                                                                                              alt="MSMCT.">
                                                                                                                                                                                                                                                                                                                                                      <span><b>MSMCT: Multi-State Multi-Camera Tracker</b>
                                                                                                                                                                                                                                                                                                                                                  <br><b>Behzad Bozorgtabar</b>, Roland Goecke
                                                                                                                                                                                                                                                                                                                                                  <br>IEEE TCSVT 2018
                                                                                                                                                                                                                                                                                                                                                  <br> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8048028">paper</a>



<!-- <tr><center>
        <p class="paper"><video loop autoplay muted>
            <source src="images/hessian.mp4" type="video/mp4">
        </video>
            <span><b>The Hessian Penalty: A Weak Prior for Unsupervised Disentanglement</b>
        <br>William Peebles, John Peebles, Jun-Yan Zhu, Alexei Efros, Antonio Torralba
        <br>ECCV 2020 (Spotlight)
                <br> <a href="https://youtu.be/uZyIcTkSSXA">video</a> &#183; <a href="https://youtu.be/jPl-0EN6S1w">overview in 90 seconds</a> &#183; <a href="hessian-penalty.html">project page</a> &#183; <a href="https://arxiv.org/abs/2008.10599">paper</a> &#183; <a href="https://github.com/wpeebles/hessian_penalty">github</a></span></p>
                <!-- </center></tr> -->



<!-- <tr><center>
        <p class="paper"><img src="images/sig2019.png"
                              alt="A natural image of a building is modified by adding trees and domes.">
            <span><b>Semantic Photo Manipulation with a Generative Image Prior</b>
        <br>David Bau, Hendrik Strobelt, William Peebles, Jonas Wulff, Bolei Zhou, Jun-Yan Zhu, Antonio Torralba
        <br>SIGGRAPH 2019<br><a href="http://ganpaint.io/demo/?project=church">demo</a> &#183;
        <a href="http://ganpaint.io/Bau_et_al_Semantic_Photo_Manipulation_preprint.pdf">paper</a> &#183;
        <a href="http://ganpaint.io/">overview</a></span></p>
<!-- </center></tr> -->
<h2 style="background: linear-gradient(180deg, rgba(255,255,255,0) 65%, #ffcd8c 65%);">Grants</h2><br>

<table style="border-spacing:2px">

    <tbody>
      <tr><td> Personalized Health and Related Technologies (PHRT)</td></tr>
    <tr><td> Swiss Cancer League</td></tr>
    <tr><td> Discovery Translation Fund (DTF 2.0)</td></tr>
  </tbody>
</table>

<h2 style="background: linear-gradient(180deg, rgba(255,255,255,0) 65%, #add8e6 65%);">PhD Students</h2><br>

<table style="border-spacing:2px">

    <tbody>
      <tr><td> <a href="https://people.epfl.ch/thomas.stegmuller?lang=en">Thomas Stegmüller</a></td></tr>
    <tr><td> <a href="https://people.epfl.ch/guillaume.vray?lang=en">Guillaume Vray</a></td></tr>
    <tr><td> <a href="https://people.epfl.ch/devavrat.tomar?lang=en">Devavrat Tomar</a></td></tr>
  </tbody>
</table>

<h2 style="background: linear-gradient(180deg, rgba(255,255,255,0) 65%, #8cfffb 65%);">Current Teaching</h2><br>

<table id="tbTeaching" border="0" width="100%">
	<tbody>
		<tr>
			<td> 2019-Present</td><td>Image analysis and pattern recognition (EE-451-4 ECTS- Bozorgtabar &
Thiran), EPFL </td>
		</tr>
		<tr>
			<td> 2019-Present</td><td>Lab in signal and image processing (EE-490(f)-4 ECTS- Bozorgtabar & Thiran), EPFL</td>
		</tr>

	</tbody>
</table>

    </body>

    <div id="footer">
    	<div id="footer-text"></div>
    </div>
    	<p><center>
          	<div id="clustrmaps-widget" style="width:10%">

              <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=s99PAjUbyKsvGkd9kZqSAJUKuVx8PqiTpvJ3gAQj7mA"></script>
          		<noscript><a href='https://clustrmaps.com/site/xfn5'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=a&t=tt&d=pT8r_ZMBBdBPTv7KnlTCiBDylmHyi1qsWdPpY_tIlqY'/></a></noscript>



    <!--<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=UexA6kPrFZuJeB69B5BZyS063R_EhdDx6FAwAYiub2U&co=2d78ad&ct=ffffff&cmo=3acc3a&cmn=ff5353'></script>
          		<noscript><a href='https://clustrmaps.com/site/1aa2l'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=a&t=tt&d=UexA6kPrFZuJeB69B5BZyS063R_EhdDx6FAwAYiub2U&co=2d78ad&ct=ffffff'/></a></noscript> -->
    	</div>
    	<br>
            &copy; Template from William Peebles. Behzad Bozorgtabar | Last updated: October 29 2024

          </center></p>


    </div>
</html>
