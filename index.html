<!DOCTYPE html>
<html>
    <head>
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-176302866-1"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'UA-176302866-1');
        </script>

        <meta charset="utf-8">
        <title>Behzad Bozorgtabar</title>
        <meta name="description" content="Project Page">
        <link rel="stylesheet" href="main.css">
        <link rel="stylesheet" href="https://use.typekit.net/oml3bsz.css">
    </head>
    <body>
        <h1>
            Behzad Bozorgtabar
        </h1><br>
        <h3> Computer Vision Group Leader & Lecturer at EPFL<br>
          Senior Scientist at CHUV-EPFL </h3><br>
        <div class="row">
            <div class="column-left">
                <img class="me" src="images/BBB.png" alt="Behzad Bozorgtabar"><br>
                email: behzad.bozorgtabar [at] epfl [dot] ch <br>
                <p> <a href="https://scholar.google.com/citations?user=kxAk6AoAAAAJ"><img src="./pic/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
        					<a href="https://github.com/BehzadBozorgtabar"><img src="./pic/github_s.jpg" height="30px" style="margin-bottom:-3px"></a>
                  <a href="https://dblp.org/pid/59/10419.html"><img src="./pic/dblp.png" height="30px" style="margin-bottom:-3px"></a>
                  <a href="https://www.linkedin.com/in/behzad-bozorgtabar-72838560/"><img src="./pic/LinkedIn_s.png" height="30px" style="margin-bottom:-3px"></a>
        				</p>
            </div>
            <!--<div class="column-right pxb">
            <a href="https://github.com/BehzadBozorgtabar/SELF-TAUGHT-SEMI-SUPERVISED-ANOMALY-DETECTION">github</a></span></p>
                <h1>THE PIXEL BENDING BLOG</h1>
                <p>Welcome to the Pixel Bending mini-blog! Here, I'll talk about various topics related to synthesizing images,
                    building deep generative models and more. Click the links below to access the posts:</p>
                <a class="disentangle-button gradient-button" href="blog_posts/disentanglement.html">1. THE MAGIC OF DISENTANGLEMENT</>
                <a class="hessian-button gradient-button">2. THE HESSIAN PENALTY</a>
            </div>-->

            <div class="column-right pxb">
                <h1>RESEARCH UPDATES</h1>
                <p><img style="width:60px; height:60px;" class="middle" src="images/unmix_tns.gif"><b>ICLR 2024 paper: 'Un-Mixing Test-Time Normalization Statistics: Combatting Label Temporal Correlation'</b></p><br>
                <a class="disentangle-button gradient-button" href="https://openreview.net/pdf?id=xyxU99Nutg">UnMix-TNS</a>
                <p><img style="width:60px; height:60px;" class="middle" src="images/cribo_logo.png"> <b>ICLR 2024 paper: 'CrIBo: Self-Supervised Learning via Cross-Image Object-Level Bootstrapping'</b></p><br>
                <a class="disentangle-button gradient-button" href="https://openreview.net/pdf?id=3M0GXoUEzP">CrIBo</a>


                <!--<h1>RESEARCH UPDATES</h1>
                <p><img style="width:60px; height:60px;" class="middle" src="images/Crocodile.gif"> <b>CVPR 2023 paper: 'CrOC: Cross-View Online Clustering for Dense Visual Representation Learning'</b></p><br>
                <a class="disentangle-button gradient-button" href="CrOC.html">CrOC</a>
                <p><img style="width:60px; height:60px;" class="middle" src="images/tesla.gif"> <b>CVPR 2023 paper: 'TeSLA: Test-Time Self-Learning With Automatic Adversarial Augmentation'</b></p><br>
                <a class="disentangle-button gradient-button" href="TeSLA.html">TeSLA</a>>-->

            </div>

        </div>
        <br>
        <h2 style="background: linear-gradient(180deg, rgba(255,255,255,0) 65%, #ff8888 65%);">About Me</h2><br>

        I'm a senior scientist and lecturer at the Signal Processing Lab (LTS5) at the Swiss Federal Institute of Technology (EPFL), with a joint affiliation with the Department of Radiology at the Lausanne University Hospital (CHUV) in Lausanne, Switzerland. At the EPFL-LTS5, I am the computer vision team leader for the medical imaging group. I am a member of <a href="https://ellis.eu/members"> European Lab for Learning & Intelligent Systems (ELLIS)</a> and <a href="https://www.epfl.ch/research/domains/epfl-ellis/ellis-society-members/"> EPFL’s ELLIS Unit</a>. Earlier, I was a Postdoctoral Researcher at IBM Research-Australia.



          <p> My principal research area lies at the intersection of computer vision and medical image analysis and machine learning. I have a strong interest in <b>self-supervised methodologies</b> on learning from limited data or labels, which I consider major avenues for
            innovation and impact for many vision-based applications. The ultimate goal of my research is to build next-generation intelligent machines that will tackle many of the most challenging problems in responsible AI, including reliability, generalization, and overcoming the hurdles posed by data and annotation scarcity. My aim is to ensure that AI systems are robust and reliable enough for deployment in critical, real-world applications.</p><br><br>
        <h2 style="background: linear-gradient(180deg, rgba(255,255,255,0) 65%, #fffe8c 65%);">News</h2><br>

        <!--<b>[July 2020]</b> I started a blog! It's called Pixel Bending, and I'll be discussing various things related to generative models.
        The first two-part series is on disentanglement.<br>href="https://www.sciepublish.com/index/journals/editors/cvml/21.html">-->
        <b><font color="red">[Jan 2024]</font></b> Our paper 'UnMix-TNS', Un-Mixing Test-Time Normalization Statistics: Combatting Label Temporal Correlation has received acceptance from ICLR 2024.<br>
        <b><font color="red">[Jan 2024]</font></b> Our paper 'CrIBo', Self-Supervised Learning Via Cross-Image Object-Level Bootstrapping has received acceptance from ICLR 2024.<br>
        <b><font color="red">[Jan 2024]</font></b> Our paper 'Distill-SODA' has been accepted for publication in the IEEE Transactions on Medical Imaging (T-MI).<br>
        <b><font color="red">[Jan 2024]</font></b> Our joint paper, titled 'GANDALF: Graph Transformers for Multi-Label Chest X-ray Classification, has been accepted for publication in the Medical Image Analysis journal.<br>
        <b><font color="red">[Dec 2023]</font></b> Our joint paper on Graph Transformers has received acceptance from AAAI 2024.<br>
        <b><font color="red">[Dec 2023]</font></b> Our self-supervised learning-based cervical cytology paper has been accepted in the Computers in Biology and Medicine journal.<br>
        <!--<b><font color="red">[July 2023]</font></b> Our joint work with KU Leuven, AdaSim: Adaptive Similarity Bootstrapping for Self-Distillation based Representation Learning, has received acceptance from ICCV 2023.<br>
        <b><font color="red">[July 2023]</font></b> Our joint work with IBM Zurich Research Lab, Weakly Supervised Joint Whole-Slide Segmentation and Classification in Prostate Cancer, has received acceptance from journal of Medical Image Analysis (MedIA).<br>
        <!--<b><font color="red">[June 2023]</font></b> Two papers have received acceptance from MICCAI 2023.<br>
        <b><font color="red">[Feb 2023]</font></b> Our paper, TeSLA: Test-Time Self-Learning With Automatic Adversarial Augmentation, has received acceptance from CVPR 2023.<br>
        <b><font color="red">[Feb 2023]</font></b> Our paper, CrOC: Cross-View Online Clustering for Dense Visual Representation Learning, has received acceptance from CVPR 2023.<br>
        <!--<b>[<b>[Jan 2023]</b> Our joint work with the University of Bern, namely 'SAGTTA' on test-time augmentation, has been accepted to ISBI 2023.<br>
        [Nov 2022]</b> Our paper on self-supervised anomaly localization has received acceptance from AAAI 2023 (acceptance rate of 19.6%) (Oral).<br>
        <b>[Oct 2022]</b> Our paper won First Runner up award at the AIMIA Workshop at ECCV 2022.<br>
        <b>[Oct 2022]</b> Our new paper, ScoreNet, has received acceptance from WACV 2023.<br>
        <!--<b>[Sep 2022]</b> Our new paper on transformer-based anomaly detection and localization has received acceptance from BMVC 2022.<br>
        <!--<b><b>[Aug 2022]</b> My patent on system and method for domain adaptation has been published.</a><br>
        [<b>[Aug 2022]</b> Two papers have received acceptance from ECCV 2022  AIMIA Workshop</a>.<br>
        <b>[Aug 2022]</b> My patent on annotation-efficient image anomaly detection has been published.</a><br>
        July 2020]</b> I started a blog! It's called Pixel Bending, and I'll be discussing various things related to generative models.
        The first two-part series is on disentanglement.<br>href="https://www.sciepublish.com/index/journals/editors/cvml/21.html">
        <b>[May 2022]</b> I joined the editorial board of a Journal of Computer Vision and Machine Learning</a>.<br>
        <b>[Apr 2022]</b> Code for the OptTTA has been released in PyTorch <a href="https://github.com/devavratTomar/OptTTA"> here</a>.<br>
        <b>[Mar 2022]</b> Our new paper, OptTTA, has received acceptance from MIDL 2022 for an oral presentation.<br>-->


       <h2 style="background: linear-gradient(180deg, rgba(255,255,255,0) 65%, #cd8cff 65%);">EPFL Computer Vision Talks</h2><br>
       <p class="paper"><img src="images/TALKS.png"
                             alt="EPFL CV Talks.">
           <span><b>I am organizing the EPFL Computer Vision Talks</b>
       <br><a href="https://www.youtube.com/channel/UCAkp-rlUGYkpdIqmKezamWw/videos">YouTube Channel</a> </span></p>

       <h2 style="background: linear-gradient(180deg, rgba(255,255,255,0) 65%, #8ca9ff 65%);">Citations</h2><br>
       <p class="paper"><img src="images/citation_updated.png"
                             alt="citations.">
           <span><b>A complete list of my publications and patents can be found at </b>
       <a href="https://scholar.google.com/citations?view_op=list_works&hl=en&user=kxAk6AoAAAAJ&gmla=AJsN-F7ChUXZmlbUjbrqc1qsOC_ETzCYHSofHkiyiwD9wqLtXswlrGvYRW3LraC0IEF11euu9IZagFBrJWlAoI1OLnTW5ZUMHgLlhwyVYuys03rvbNlVlmzBpuKNVK9RSNOatjiKnp8r">Google Scholar</a> </span></p>



       <h2 style="background: linear-gradient(180deg, rgba(255,255,255,0) 65%, #93fc93 65%);">Recent Selected Publications</h2><br>

       <p class="paper"><img src="images/unmix_tns.gif"
         width="200"
height="200" alt="UnMix">
       <span><b><font color="red">*New*</font> Un-Mixing Test-Time Normalization Statistics: Combatting Label Temporal Correlation</b>
       <br>Devavrat Tomar<sup>*</sup>, Guillaume Vray<sup>*</sup>, Jean-Philippe Thiran, <b>Behzad Bozorgtabar</b>
         <br>ICLR 2024
         <br>   <a href="https://openreview.net/pdf?id=xyxU99Nutg">paper</a> &#183; <a href="https://github.com/devavratTomar/unmixtns">github</a> </span></p>


         <p class="paper"><img src="images/CrIBo.png"
                         alt="CrIBo">
         <span><b><font color="red">*New*</font> CrIBo: Self-Supervised Learning via Cross-Image Object-Level Bootstrapping</b>
         <br>Tim Lebailly<sup>*</sup>, Thomas Stegmüller<sup>*</sup>, <b>Behzad Bozorgtabar</b>, Jean-Philippe Thiran, Tinne Tuytelaars</b>
           <br>ICLR 2024 (<b>Spotlight, Top 5%</b>)
           <br>   <a href="https://openreview.net/pdf?id=3M0GXoUEzP">paper</a> &#183; <a href="https://github.com/tileb1/CrIBo">github</a> </span></p>


      <p class="paper"><img src="images/Distill_SODA.png"
                       alt="Distill_SODA">
       <span><b><font color="red">*New*</font> Distill-SODA: Distilling Self-Supervised Vision Transformer for Source-Free Open-Set Domain Adaptation in Computational Pathology</b>
       <br>Guillaume Vray<sup>*</sup>, Devavrat Tomar<sup>*</sup>, Jean-Philippe Thiran, <b>Behzad Bozorgtabar</b>
       <br>IEEE Transactions on Medical Imaging (T-MI) 2024
       <br>   <a href="https://arxiv.org/pdf/2307.04596.pdf">paper</a> </span></p>



       <p class="paper"><img src="images/iccv2023.png"
                       alt="Adasim">
       <span><b><font color="red">*New*</font> Adaptive Similarity Bootstrapping for Self-Distillation based Representation Learning</b>
       <br>Tim Lebailly<sup>*</sup>, Thomas Stegmüller<sup>*</sup>, <b>Behzad Bozorgtabar</b>, Jean-Philippe Thiran, Tinne Tuytelaars</b>
         <br>ICCV 2023
         <br>   <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Lebailly_Adaptive_Similarity_Bootstrapping_for_Self-Distillation_Based_Representation_Learning_ICCV_2023_paper.pdf">paper</a> &#183; <a href="https://github.com/tileb1/AdaSim">github</a></span></p>


        <p class="paper"><img src="images/CrOC_main.png"
                        alt="CrOC_main">
        <span><b> CrOC: Cross-View Online Clustering for Dense Visual Representation Learning</b>
        <br>Thomas Stegmüller<sup>*</sup>, Tim Lebailly<sup>*</sup>, <b>Behzad Bozorgtabar</b>, Tinne Tuytelaars, Jean-Philippe Thiran</b>
          <br>CVPR 2023
          <br>  <a href="CrOC.html">project page</a> &#183; <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Stegmuller_CrOC_Cross-View_Online_Clustering_for_Dense_Visual_Representation_Learning_CVPR_2023_paper.pdf">paper</a> &#183; <a href="https://github.com/stegmuel/CrOC">github</a></span></p>


        <p class="paper"><img src="images/TeSLA_main.png"
                        alt="TeSLA_main">
        <span><b>TeSLA: Test-Time Self-Learning With Automatic Adversarial Augmentation</b>
        <br>Devavrat Tomar<sup>*</sup>, Guillaume Vray<sup>*</sup>, <b>Behzad Bozorgtabar</b>, Jean-Philippe Thiran
          <br>CVPR 2023
          <br>   <a href="TeSLA.html">project page</a> &#183; <a href="https://arxiv.org/pdf/2303.09870.pdf">paper</a> &#183; <a href="https://github.com/devavratTomar/TeSLA">github</a></span></p>



          <p class="paper"><img src="images/amae.png"
                          alt="AMAE">
          <span><b> AMAE: Adaptation of Pre-Trained Masked Autoencoder for Dual-Distribution Anomaly Detection in Chest X-Rays</b>
          <br><b>Behzad Bozorgtabar</b>, Dwarikanath Mahapatra, Jean-Philippe Thiran</b>
            <br>MICCAI 2023
            <br>   <a href="https://arxiv.org/pdf/2307.12721.pdf">paper</a> </span></p>

        <p class="paper"><img src="images/scorenet_2.png"
                        alt="ScoreNet">
        <span><b>ScoreNet: Learning Non-Uniform Attention and Augmentation for <br>Transformer-Based Histopathological Image Classification</b>
        <br>Thomas Stegmüller, <b>Behzad Bozorgtabar</b>, Antoine Spahr, Jean-Philippe Thiran</b>
          <br>WACV 2023
          <br>  <a href="ScoreNet.html">project page</a> &#183; <a href="https://openaccess.thecvf.com/content/WACV2023/papers/Stegmuller_ScoreNet_Learning_Non-Uniform_Attention_and_Augmentation_for_Transformer-Based_Histopathological_Image_WACV_2023_paper.pdf">paper</a> &#183; <a href="https://github.com/stegmuel/ScoreNet">github</a> </span></p>

          <p class="paper"><img src="images/BMVC_2022.png"
                          alt="ANOM">
          <span><b>Anomaly Detection and Localization Using Attention-Guided Synthetic Anomaly <br>and Test-Time Adaptation</b>
          <br><b>Behzad Bozorgtabar</b>, Dwarikanath Mahapatra, Jean-Philippe Thiran</b>
            <br>BMVC 2022
            <br>  <a href="https://bmvc2022.mpi-inf.mpg.de/0472.pdf">paper</a>  </span></p>

              <p class="paper"><img src="images/optTTA.png"
                              alt="OptTTA">
            <span><b> OptTTA: Learnable Test-Time Augmentation for <br>Source-Free Medical Image Segmentation Under Domain Shift</b>
        <br>Devavrat Tomar, Guillaume Vray, Jean-Philippe Thiran, <b>Behzad Bozorgtabar</b>
                <br>MIDL 2022 (Oral)
                <br>   <a href="OptTTA.html">project page</a> &#183; <a href="https://openreview.net/pdf?id=B6HdQaY_iR">paper</a> &#183; <a href="https://github.com/devavratTomar/OptTTA">github</a></span></p>



                  <p class="paper"><img src="images/SRMA.png"
                                        alt="SRMA.">
                      <span><b> Self-Rule to Multi-Adapt: Generalized Multi-source Feature Learning <br>Using Unsupervised Domain Adaptation for Colorectal Cancer Tissue Detection</b>
                  <br>Christian Abbet, Linda Studer, Andreas Fischer, Heather Dawson, Inti Zlobec,<br>
                  <b>Behzad Bozorgtabar</b>, Jean-Philippe Thiran
                  <br>MedIA Journal 2022
                  <br> <a href="https://www.sciencedirect.com/science/article/pii/S1361841522001207?utm_campaign=STMJ_AUTH_SERV_PUBLISHED&utm_medium=email&utm_acid=90864309&SIS_ID=&dgcid=STMJ_AUTH_SERV_PUBLISHED&CMX_ID=&utm_in=DM256431&utm_source=AC_">paper</a> &#183;
                          <a href="https://github.com/christianabbet/SRA">github</a></span></p>

                      <p class="paper"><img src="images/wacv_2022.png"
                                                alt="SST.">
                              <span><b>Self-Supervised Generative Style Transfer for One-Shot Medical Image Segmentation</b>
                          <br>Devavrat Tomar, <b>Behzad Bozorgtabar</b>, Manana Lortkipanidze, Guillaume Vray, <br>Mohammad Saeed Rad, Jean-Philippe Thiran
                          <br>WACV 2022
                          <br> <a href="https://openaccess.thecvf.com/content/WACV2022/papers/Tomar_Self-Supervised_Generative_Style_Transfer_for_One-Shot_Medical_Image_Segmentation_WACV_2022_paper.pdf">paper</a> &#183;
                                  <a href="https://github.com/devavratTomar/SST/">github</a></span></p>

                                  <p class="paper"><img src="images/SegGini.png"
                                                            alt="SegGini.">
                                          <span><b>Learning Whole-Slide Segmentation from Inexact and <br> Incomplete Labels using Tissue Graphs</b>
                                      <br>Valentin Anklin, Pushpak Pati, Guillaume Jaume, <b>Behzad Bozorgtabar</b>, <br> Antonio Foncubierta-Rodríguez, Jean-Philippe Thiran, Mathilde Sibony,<br> Maria Gabrani, Orcun Goksel
                                      <br>MICCAI 2021
                                      <br> <a href="https://link.springer.com/content/pdf/10.1007/978-3-030-87196-3_59.pdf">paper</a> &#183;
                                              <a href="https://github.com/histocartography/histocartography">github</a></span></p>

                                    <p class="paper"><img src="images/SOoD.png"
                                                              alt="SOoD.">
                                                      <span><b>SOoD: Self-Supervised Out-of-Distribution Detection <br>Under Domain Shift for Multi-Class Colorectal Cancer Tissue Types</b>
                                                  <br><b>Behzad Bozorgtabar</b>, Guillaume Vray, Dwarikanath Mahapatra, Jean-Philippe Thiran
                                                  <br>ICCVW 2021
                                                  <br> <a href="https://openaccess.thecvf.com/content/ICCV2021W/CVAMD/papers/Bozorgtabar_SOoD_Self-Supervised_Out-of-Distribution_Detection_Under_Domain_Shift_for_Multi-Class_Colorectal_ICCVW_2021_paper.pdf">paper</a> &#183;
                                                          <a href="https://github.com/GuillaumeVray/SOoD">github</a></span></p>

                                                          <p class="paper"><img src="images/arxiv.png"
                                                                                    alt="CVPR2021.">
                                                                            <span><b>Quantifying Explainers of Graph Neural Networks in Computational Pathology</b>
                                                                        <br>Guillaume Jaume, Pushpak Pati, <b>Behzad Bozorgtabar</b>, Antonio Foncubierta-Rodríguez, <br>Florinda Feroce, Anna Maria Anniciello, Tilman Rau, Maria Gabrani, <br>Jean-Philippe Thiran, Orcun Goksel
                                                                        <br>CVPR 2021
                                                                        <br> <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Jaume_Quantifying_Explainers_of_Graph_Neural_Networks_in_Computational_Pathology_CVPR_2021_paper.pdf">paper</a> &#183;
                                                                                <a href="https://github.com/histocartography/patho-quant-explainer">github</a></span></p>


                                                                                <p class="paper"><img src="images/tmi.png"
                                                                                                          alt="T-MI.">
                                                                                                  <span><b>Self-Attentive Spatial Adaptive Normalization for Cross-Modality Domain Adaptation</b>
                                                                                              <br>Devavrat Tomar, Manana Lortkipanidze, Guillaume Vray, <br> <b>Behzad Bozorgtabar</b>, Jean-Philippe Thiran
                                                                                              <br>IEEE Transactions on Medical Imaging (T-MI) 2021
                                                                                              <br> <a href="https://ieeexplore.ieee.org/document/9354186">paper</a> &#183;
                                                                                                      <a href="https://github.com/devavratTomar/sasan">github</a></span></p>

                                                                                                      <p class="paper"><img src="images/midl.png"
                                                                                                                                alt="MIDL2021.">
                                                                                                                        <span><b>Self-Rule to Adapt: Learning Generalized Features from Sparsely-Labeled Data<br> Using Unsupervised Domain Adaptation for Colorectal Cancer Tissue Phenotyping</b>
                                                                                                                    <br>Christian Abbet, Linda Studer, Andreas Fischer, Heather Dawson, Inti Zlobec,<br>
                                                                                                                    <b>Behzad Bozorgtabar</b>, Jean-Philippe Thiran
                                                                                                                    <br>MIDL 2021
                                                                                                                    <br> <a href="https://2021.midl.io/proceedings/abbet21.pdf">paper</a> &#183;
                                                                                                                            <a href="https://github.com/christianabbet/SRA">github</a></span></p>

                                                                                                                            <p class="paper"><img src="images/isbi2021.png"
                                                                                                                                                      alt="ISBI2021.">
                                                                                                                                              <span><b>Self-Taught Semi-Supervised Anomaly Detection on Upper Limb X-rays</b>
                                                                                                                                          <br>Antoine Spahr , <b>Behzad Bozorgtabar</b>, Jean-Philippe Thiran
                                                                                                                                          <br>ISBI 2021
                                                                                                                                          <br> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9433771">paper</a>&#183;
                                                                                                                                          <a href="https://github.com/BehzadBozorgtabar/SELF-TAUGHT-SEMI-SUPERVISED-ANOMALY-DETECTION">github</a></span></p>


                                                                                                                                                  <p class="paper"><img src="images/wacv20.png"
                                                                                                                                                                            alt="ISBI2021.">
                                                                                                                                                                    <span><b>Benefiting from Bicubically Down-Sampled Images for <br>Learning Real-World Image Super-Resolution</b>
                                                                                                                                                                <br>Mohammad Saeed Rad, Thomas Yu, Claudiu Musat, Hazım Kemal Ekenel, <br> <b>Behzad Bozorgtabar</b>, Jean-Philippe Thiran
                                                                                                                                                                <br>WACV 2021
                                                                                                                                                                <br> <a href="https://openaccess.thecvf.com/content/WACV2021/papers/Rad_Benefiting_From_Bicubically_Down-Sampled_Images_for_Learning_Real-World_Image_Super-Resolution_WACV_2021_paper.pdf">paper</a>
                                                                                                                                                                    </span></p>

                                                                                                                                                                    <p class="paper"><img src="images/miccai20_1.png"
                                                                                                                                                                                              alt="SALAD.">
                                                                                                                                                                                      <span><b>SALAD: Self-Supervised Aggregation Learning for Anomaly Detection on X-Rays</b>
                                                                                                                                                                                  <br><b>Behzad Bozorgtabar</b>, Dwarikanath Mahapatra, Guillaume Vray, Jean-Philippe Thiran
                                                                                                                                                                                  <br>MICCAI 2020
                                                                                                                                                                                  <br> <a href="https://link.springer.com/content/pdf/10.1007%2F978-3-030-59710-8_46.pdf">paper</a> &#183;
                                                                                                                                                                                          <a href="https://github.com/GuillaumeVray/SALAD">github</a></span></p>

                                                                                                                                                                                          <p class="paper"><img src="images/miccai20_2.png"
                                                                                                                                                                                                                    alt="Self-Rule.">
                                                                                                                                                                                                            <span><b>Divide-and-Rule: Self- Supervised Learning for Survival Analysis in Colorectal Cancer</b>
                                                                                                                                                                                                        <br>Christian Abbet, Inti Zlobec, <b>Behzad Bozorgtabar</b>, Jean-Philippe Thiran
                                                                                                                                                                                                        <br>MICCAI 2020
                                                                                                                                                                                                        <br> <a href="https://link.springer.com/content/pdf/10.1007/978-3-030-59722-1_46.pdf">paper</a> &#183;
                                                                                                                                                                                                                <a href="https://github.com/christianabbet/DnR">github</a></span></p>


                                                                                                                                                                                                                <p class="paper"><img src="images/cvpr2020.png"
                                                                                                                                                                                                                                          alt="CVPR2020.">
                                                                                                                                                                                                                                  <span><b>Pathological Retinal Region Segmentation From OCT Images <br>Using Geometric Relation Based Augmentation</b>
                                                                                                                                                                                                                              <br>Dwarikanath Mahapatra, <b>Behzad Bozorgtabar</b>, Jean-Philippe Thiran, Ling Shao
                                                                                                                                                                                                                              <br>CVPR 2020
                                                                                                                                                                                                                              <br> <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Mahapatra_Pathological_Retinal_Region_Segmentation_From_OCT_Images_Using_Geometric_Relation_CVPR_2020_paper.pdf">paper</a>


                                                                                                                                                                                                                              <p class="paper"><img src="images/syndemo.png"
                                                                                                                                                                                                                                                        alt="Syndemo.">
                                                                                                                                                                                                                                                <span><b>SynDeMo: Synergistic Deep Feature Alignment for Joint Learning of Depth and Ego-Motion</b>
                                                                                                                                                                                                                                            <br><b>Behzad Bozorgtabar</b>, Mohammad Saeed Rad, Dwarikanath Mahapatra, Jean-Philippe Thiran
                                                                                                                                                                                                                                            <br>ICCV 2019
                                                                                                                                                                                                                                            <br> <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Bozorgtabar_SynDeMo_Synergistic_Deep_Feature_Alignment_for_Joint_Learning_of_Depth_ICCV_2019_paper.pdf">paper</a> &#183;
                                                                                                                                                                                                                                                    <a href="http://openaccess.thecvf.com/content_ICCV_2019/supplemental/Bozorgtabar_SynDeMo_Synergistic_Deep_ICCV_2019_supplemental.pdf">supplementary material</a></span></p>


                                                                                                                                                                                                                                                    <p class="paper"><img src="images/srobb.png"
                                                                                                                                                                                                                                                                              alt="SROBB.">
                                                                                                                                                                                                                                                                      <span><b>SROBB: Targeted Perceptual Loss for Single Image Super-Resolution</b>
                                                                                                                                                                                                                                                                  <br>Mohammad Saeed Rad, <b>Behzad Bozorgtabar</b>, Urs-Viktor Marti, <br> Max Basler, Hazım Kemal Ekenel, <br>Jean-Philippe Thiran
                                                                                                                                                                                                                                                                  <br>ICCV 2019
                                                                                                                                                                                                                                                                  <br> <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Rad_SROBB_Targeted_Perceptual_Loss_for_Single_Image_Super-Resolution_ICCV_2019_paper.pdf">paper</a> &#183;
                                                                                                                                                                                                                                                                          <a href="http://openaccess.thecvf.com/content_ICCV_2019/supplemental/Rad_SROBB_Targeted_Perceptual_ICCV_2019_supplemental.pdf">supplementary material</a></span></p>


                                                                                                                                                                                                                                                                          <p class="paper"><img src="images/fg19.png"
                                                                                                                                                                                                                                                                                                    alt="FG2019.">
                                                                                                                                                                                                                                                                                            <span><b>Using Photorealistic Face Synthesis and Domain Adaptation <br>to Improve Facial Expression Analysis</b>
                                                                                                                                                                                                                                                                                        <br><b>Behzad Bozorgtabar</b>, Mohammad Saeed Rad, Hazım Kemal Ekenel, Jean-Philippe Thiran
                                                                                                                                                                                                                                                                                        <br>FG 2019
                                                                                                                                                                                                                                                                                        <br> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8756632&tag=1">paper</a> &#183;
                                                                                                                                                                                                                                                                                                <a href="https://github.com/BehzadBozorgtabar/FSDA">github</a></span></p>


                                                                                                                                                                                                                                                                                                <p class="paper"><img src="images/l2s19.jpg"
                                                                                                                                                                                                                                                                                                                          alt="CVIU2019.">
                                                                                                                                                                                                                                                                                                                  <span><b>Learn to Synthesize and Synthesize to Learn</b>
                                                                                                                                                                                                                                                                                                              <br><b>Behzad Bozorgtabar</b>, Mohammad Saeed Rad, Hazım Kemal Ekenel, Jean-Philippe Thiran
                                                                                                                                                                                                                                                                                                              <br>CVIU 2019
                                                                                                                                                                                                                                                                                                              <br> <a href="https://www.sciencedirect.com/science/article/pii/S1077314219300657?via%3Dihub">paper</a> &#183;
                                                                                                                                                                                                                                                                                                                      <a href="https://github.com/BehzadBozorgtabar/Learn-to-Synthesize-and-Synthesize-to-Learn">github</a></span></p>



                                                                                                                                                                                                                                                                                                                      <p class="paper"><img src="images/NeurIPS18.png"
                                                                                                                                                                                                                                                                                                                                                alt="NeurIPS18.">
                                                                                                                                                                                                                                                                                                                                        <span><b>Image-Level Attentional Context Modeling Using Nested-Graph Neural Networks</b>
                                                                                                                                                                                                                                                                                                                                    <br>Guillaume Jaume, <b>Behzad Bozorgtabar</b>, Hazım Kemal Ekenel, <br>Jean-Philippe Thiran, Maria Gabrani
                                                                                                                                                                                                                                                                                                                                    <br>NeurIPS 2018
                                                                                                                                                                                                                                                                                                                                    <br> <a href="https://arxiv.org/pdf/1811.03830.pdf">paper</a>


                                                                                                                                                                                                                                                                                                                                    <p class="paper"><img src="images/msmct.png"
                                                                                                                                                                                                                                                                                                                                                              alt="MSMCT.">
                                                                                                                                                                                                                                                                                                                                                      <span><b>MSMCT: Multi-State Multi-Camera Tracker</b>
                                                                                                                                                                                                                                                                                                                                                  <br><b>Behzad Bozorgtabar</b>, Roland Goecke
                                                                                                                                                                                                                                                                                                                                                  <br>IEEE TCSVT 2018
                                                                                                                                                                                                                                                                                                                                                  <br> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8048028">paper</a>



<!-- <tr><center>
        <p class="paper"><video loop autoplay muted>
            <source src="images/hessian.mp4" type="video/mp4">
        </video>
            <span><b>The Hessian Penalty: A Weak Prior for Unsupervised Disentanglement</b>
        <br>William Peebles, John Peebles, Jun-Yan Zhu, Alexei Efros, Antonio Torralba
        <br>ECCV 2020 (Spotlight)
                <br> <a href="https://youtu.be/uZyIcTkSSXA">video</a> &#183; <a href="https://youtu.be/jPl-0EN6S1w">overview in 90 seconds</a> &#183; <a href="hessian-penalty.html">project page</a> &#183; <a href="https://arxiv.org/abs/2008.10599">paper</a> &#183; <a href="https://github.com/wpeebles/hessian_penalty">github</a></span></p>
                <!-- </center></tr> -->



<!-- <tr><center>
        <p class="paper"><img src="images/sig2019.png"
                              alt="A natural image of a building is modified by adding trees and domes.">
            <span><b>Semantic Photo Manipulation with a Generative Image Prior</b>
        <br>David Bau, Hendrik Strobelt, William Peebles, Jonas Wulff, Bolei Zhou, Jun-Yan Zhu, Antonio Torralba
        <br>SIGGRAPH 2019<br><a href="http://ganpaint.io/demo/?project=church">demo</a> &#183;
        <a href="http://ganpaint.io/Bau_et_al_Semantic_Photo_Manipulation_preprint.pdf">paper</a> &#183;
        <a href="http://ganpaint.io/">overview</a></span></p>
<!-- </center></tr> -->
<h2 style="background: linear-gradient(180deg, rgba(255,255,255,0) 65%, #ffcd8c 65%);">Grants</h2><br>

<table style="border-spacing:2px">

    <tbody>
      <tr><td> Personalized Health and Related Technologies (PHRT)</td></tr>
    <tr><td> Swiss Cancer League</td></tr>
    <tr><td> Discovery Translation Fund (DTF 2.0)</td></tr>
  </tbody>
</table>

<h2 style="background: linear-gradient(180deg, rgba(255,255,255,0) 65%, #8cfffb 65%);">Teaching</h2><br>

<table id="tbTeaching" border="0" width="100%">
	<tbody>
		<tr>
			<td> 2019-Present</td><td>Image analysis and pattern recognition (EE-451-4 ECTS- Bozorgtabar &
Thiran), EPFL </td>
		</tr>
		<tr>
			<td> 2019-Present</td><td>Lab in signal and image processing (EE-490(f)-4 ECTS- Bozorgtabar & Thiran), EPFL</td>
		</tr>

	</tbody>
</table>

    </body>

    <div id="footer">
    	<div id="footer-text"></div>
    </div>
    	<p><center>
          	<div id="clustrmaps-widget" style="width:10%">

              <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=s99PAjUbyKsvGkd9kZqSAJUKuVx8PqiTpvJ3gAQj7mA"></script>
          		<noscript><a href='https://clustrmaps.com/site/xfn5'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=a&t=tt&d=pT8r_ZMBBdBPTv7KnlTCiBDylmHyi1qsWdPpY_tIlqY'/></a></noscript>



    <!--<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=UexA6kPrFZuJeB69B5BZyS063R_EhdDx6FAwAYiub2U&co=2d78ad&ct=ffffff&cmo=3acc3a&cmn=ff5353'></script>
          		<noscript><a href='https://clustrmaps.com/site/1aa2l'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=a&t=tt&d=UexA6kPrFZuJeB69B5BZyS063R_EhdDx6FAwAYiub2U&co=2d78ad&ct=ffffff'/></a></noscript> -->
    	</div>
    	<br>
            &copy; Template from William Peebles. Behzad Bozorgtabar | Last updated: March 1 2024

          </center></p>


    </div>
</html>
